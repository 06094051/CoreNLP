<!--#include virtual="/header.html" -->

<center>
<h2><font color="#a40526">Stanford Arabic Parser 
<a href="http://norvig.com/java-iaq.html">IAQ</a></font></h2> 
</center>

<h3>Questions</h3>

<ol>
<li><a href="#a">What tokenization of Arabic does the parser assume?</a></li>
<li><a href="#b">What character encoding do you assume?</a></li>
<li><a href="#c">What characters are encoded?</a></li>
<li><a href="#d">What POS tag set does the parser use?</a></li>
<li><a href="#e">What phrasal category set does the parser use?</a></li>
<li><a href="#f">What's not in the box?</a></li>
<li><a href="#g">What data are the parsers trained on?</a></li>
<li><a href="#h">How well do the parsers work?</a></li>
<li><a href="#i">Can you give me some examples of how to use the parser
for Arabic?</a></li> 
<li><a href="#j">Can you get dependencies output from the Arabic parser?</a></li>
<li><a href="#k">Where does the Arabic-specific source code live?</a></li>
</ol>

<p>
<font color="gray">The grey "GALE ROSETTA" notes are only for people involved
in that project; they don't apply to regular users.</font></p>

<p>
Much of the information here is also applicable to the Arabic part of
speech tagger, such as discussion of word segmentation and tag sets.
</p>

<h3>Questions with answers</h3>

<ol>
<li><h4><a name="a">What tokenization of Arabic does the parser assume?</a></h4>
<p>
The parser assumes precisely the tokenization of Arabic used in the 
<a href="http://www.ircs.upenn.edu/arabic/">Penn Arabic Treebank</a> (ATB).
<span class="cardinal"><i>You must provide input to the parser that is
tokenized in this way or 
the resulting parses will be terrible.</i></span>  We do now have a software
    component for segmenting Arabic,but you have to download and run it
    first; it isn't included in the parser (see at the end of this answer).
The Arabic parser
simply uses a whitespace tokenizer.
As far as we are aware, ATB tokenization has only an extensional definition; it
isn't written down anywhere.
Segmentation is done based on the morphological analyses generated by the 
<a href="http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2004L02">Buckwalter analyzer</a>.
The segmentation can be characterized thus:
</p>
<ul>
<li>Almost all clitics are separated off as separate words.  This includes
clitic pronouns, prepositions, and conjunctions.  However, the clitic
determiner (definite article) "Al" (ال) is <i>not</i> separated off.  Inflectional and
derivational morphology is not separated off. </li>
<li><font color="gray">[GALE ROSETTA: These separated off clitics are not overtly marked as
proclitics/enclitics, although
we do have a facility to strip off the '+' and '#' characters that the
IBM segmenter uses to mark enclitics and proclitics, respectively. See
the example below using the option <code>-escaper edu.stanford.nlp.trees.international.arabic.IBMArabicEscaper</code>]</font>
<li>Parentheses are rendered <code>-LRB-</code> and <code>-RRB-</code></li>
<li>Quotes are rendered as (ASCII) straight single and double quotes
(<code>'</code> and <code>"</code>), not as curly quotes or LaTeX-style
<!-- " -->
quotes (unlike the Penn English Treebank).</li>
<li>Dashes are represented with the ASCII hyphen character (U+002D).
<li>Non-break space is not used.
</ul>
<p>There are some tools available that can do the
necessary clitic segmentation:</p>
<ul>
<li><a href="http://nlp.stanford.edu/software/segmenter.shtml">Stanford
    Word Segmenter</a>
<li><a href="http://www1.cs.columbia.edu/~rambow/software-downloads/MADA_Distribution.html"><code>http://www1.cs.columbia.edu/~rambow/software-downloads/MADA_Distribution.html</code></a>
<li><a href="http://www1.ccls.columbia.edu/~mdiab/"><code>http://www1.ccls.columbia.edu/~mdiab/</code></a>
<li><a href="http://www.spencegreen.com/2011/01/19/howto-basic-arabic-preprocessing-for-nlp/"><code>http://www.spencegreen.com/2011/01/19/howto-basic-arabic-preprocessing-for-nlp/</code></a>
</ul>

<li><h4><a name="b">What character encoding do you assume?</a></h4>

<p>The present release provides a grammar
(<code>arabicFactored.ser.gz</code>) for real Arabic
(<code>arabicFactored.ser.gz</code>), for which the default encoding is
UTF-8, but for which another encoding (such as legacy Arabic encodings)
  can be specified on the commmand line with 
the <code>-encoding charset</code> flag.
(Previous releases also provided grammars
for the 
<a href="http://www.ldc.upenn.edu/myl/morph/buckwalter.html">Buckwalter encoding
of Arabic in ASCII</a>
(either <code>atbP3FactoredBuckwalter.ser.gz</code> or
<code>arabicFactoredBuckwalter.ser.gz</code> and
<code>atb3FactoredBuckwalter.ser.gz</code>, depending on the parser
release). They may return if there is interest.)
</p>


<li><h4><a name="c">What characters are encoded?</a></h4>

<p>The parsers are trained on unvocalized Arabic.  One grammar 
(<code>atbP3FactoredBuckwalter.ser.gz</code> or <code>atb3FactoredBuckwalter.ser.gz</code>) is
trained on input represented exactly as it is found in the Penn Arabic
Treebank.
The other grammars
(<code>arabicFactored.ser.gz</code> and 
<code>arabicFactoredBuckwalter.ser.gz</code>) are
trained on a more normalized form of Arabic.  This form deletes the
tatweel character and other diacritics beyond the short vowel markers which
are sometimes not written 
(Alef with hamza or madda becomes simply Alef, and Alef maksura becomes
Yaa), and prefers ASCII characters (Arabic punctuation and number
characters are mapped to corresponding ASCII characters).  Your accuracy
will suffer unless you normalize text in this way, because words are
recognized simply based on string identity.
<font color="gray">[GALE ROSETTA: This is precisely the mapping that the IBM
<code>ar_normalize_v5.pl</code> script does for you.]</font>

<li><h4><a name="d">What POS tag set does the parser use?</a></h4>

<p>The parser uses an "augmented Bies" tag set.  The so-called
"Bies mapping" maps down the full morphological analyses from the
Buckwalter analyzer to a subset of the POS tags used in the Penn English
Treebank (but some with different meanings).
We augment this set to represent which words have the determiner "Al" (ال)
cliticized to them.  These extra tags start with "DT", and appear for
all parts of speech that can be preceded by "Al", so we have DTNN, DTCD, etc.
This is an early definition of the <a
href="http://www.ircs.upenn.edu/arabic/Jan03release/arabic-POStags-collapse-to-PennPOStags.txt">Bies mapping</a>.
For something more up-to-date with recent updates of the Arabic Treebank tag taxonomy,
it is also be useful to look at 
<a href="http://www.ldc.upenn.edu/Catalog/docs/LDC2010T13/">the recent
documentation and articles</a>.  In particular, the Bies mapping is
defined in the file <a href="http://www.ldc.upenn.edu/Catalog/docs/LDC2010T13/atb1-v4.1-taglist-conversion-to-PennPOS-forrelease.lisp"><code>http://www.ldc.upenn.edu/Catalog/docs/LDC2010T13/atb1-v4.1-taglist-conversion-to-PennPOS-forrelease.lisp</code></a>.
</p>

<li><h4><a name="e">What phrasal category set does the parser use?</a>
</a></h4>

<p>
The set used in the Penn Arabic Treebank.  See 
<a href="http://www.ircs.upenn.edu/arabic/Jan03release/guidelines-TB-1-28-03.htm">the
original Penn
Arabic Treebank Guidelines</a>, or, better, the up-to-date
<a href="http://projects.ldc.upenn.edu/ArabicTreebank/">Penn Arabic
Treebank Guidelines</a>.
</p>

<li><h4><a name="f">What's not in the box?</a></h4>

<p>The parser download does not include components for normalizing or
  segmenting 
Arabic text.  You might look at the <a href="http://nlp.stanford.edu/software/segmenter.shtml">Stanford Word
  Segmenter</a> download, or the 
segmentation tools from 
<a href="http://www.ccls.columbia.edu/cadim/">CADIM</a>, such as the one
available on <a href="http://www1.cs.columbia.edu/~mdiab/">Mona Diab's
homepage</a> (but
note that if they also separate off the "Al" (ال) clitic, then you will need
to glue it back on in a postprocessing step).
<font color="gray">[GALE ROSETTA: IBM has an ATB segmenter and a Perl
script that does the 
appropriate normalization.  Their segmenter marks proclitics and
enclitics with '#' and '+'.  These need to be removed for parsing, but
we do provide an escaper which does this.]</font></p>

<li><h4><a name="g">What data are the parsers trained on?</a></h4>

<p>
Two of the 3 grammars
(<code>arabicFactored.ser.gz</code> and 
<code>arabicFactoredBuckwalter.ser.gz</code>) are
trained on the training data of the <a href="parser-arabic-data-splits.shtml">"Mona Diab"
(a.k.a. "Johns Hopkins 2005 Workshop") data splits</a>
of parts 1-3 of the Penn Arabic Treebank.  
The other grammar
(<code>atbP3FactoredBuckwalter.ser.gz</code> or <code>atb3FactoredBuckwalter.ser.gz</code>) is
trained on a <i>decimation</i> of the ATBp3 treebank data.  (That is,
heading sentence-by-sentence through the trees, you put 8 sentences in
training, 1 in development, and then 1 in test, and then repeat.)  This
is the data split that has been used at UPenn (see S. Kulick et al., TLT 2006).</p>
</li>

<li><h4><a name="h">How well do the parsers work?</a></h4> 

<p>The table below shows the parser's performance on the development test data sets, as
defined above.  Here, "factF1" is the Parseval F1 of Labeled Precision
and Recall, and "factDA" is the dependency accuracy of the factored
parser (based on untyped dependencies imputed from "head rules").  This is for
sentences of 40 words or less, and 
discarding "sentences" (the bylines at the start of articles) that are
just an "X" constituent.  The performance of the UTF-8 and Buckwalter
grammars is basically identical, because only the character encoding is
different (and so it is not shown separately).  Note that we do get
value from the extra data in parts 1 and 
2 of the ATB (more value than it first appears, because a decimation
data split is always advantageous to a parser), and that dependency
accuracy is relatively better than 
constituency accuracy (we regard this as evidence of inconsistent
constituency annotation in the ATB).</p> 

<center>
<pre>
                               factF1   factDA  factEx  pcfgF1  depDA   factTA   num
arabicFactored.ser.gz          77.44    84.05   13.27   69.49   80.07   96.09   1567
atb3FactoredBuckwalter.ser.gz  75.76    83.08   14.41   68.09   77.75   95.91    951
</pre>
</center>
</li>

<li><h4><a name="i">Can you give me some examples of how to use the
parser for Arabic?</a></h4>

<p>Sure!  These parsing examples are for the 3 test files supplied with the
parser.  They assume you are sitting in the root directory of the parser
distribution.  <font color="gray">[GALE ROSETTA: The last illustrates the removal of the
IBM "+" and "#" marks mentioned earlier.]</font>
</p>

<pre>
$ java -cp stanford-parser.jar -mx500m edu.stanford.nlp.parser.lexparser.LexicalizedParser arabicFactored.ser.gz arabic-onesent-utf8.txt
Loading parser from serialized file arabicFactored.ser.gz ... done [14.3 sec].
Parsing file: arabic-onesent-utf8.txt with 1 sentences.
Parsing [sent. 1 len. 8]: و نشر العدل من خلال قضاء مستقل .
(ROOT
  (S (CC و)
    (VP (VBD نشر)
      (NP (DTNN العدل))
      (PP (IN من)
        (NP (NN خلال)
          (NP (NN قضاء) (JJ مستقل)))))
    (PUNC .)))

Parsed file: arabic-onesent-utf8.txt [1 sentences].
Parsed 8 words in 1 sentences (5.15 wds/sec; 0.64 sents/sec).
$ java -cp stanford-parser.jar -mx500m edu.stanford.nlp.parser.lexparser.LexicalizedParser arabicFactoredBuckwalter.ser.gz arabic-onesent-buck.txt
Loading parser from serialized file arabicFactoredBuckwalter.ser.gz ... done [9.4 sec].
Parsing file: arabic-onesent-buck.txt with 1 sentences.
Parsing [sent. 1 len. 8]: w n$r AlEdl mn xlAl qDA' mstql .
(ROOT
  (S (CC w)
    (VP (VBD n$r)
      (NP (DTNN AlEdl))
      (PP (IN mn)
        (NP (NN xlAl)
          (NP (NN qDA') (JJ mstql)))))
    (PUNC .)))

Parsed file: arabic-onesent-buck.txt [1 sentences].
Parsed 8 words in 1 sentences (7.92 wds/sec; 0.99 sents/sec).
$ cat arabic-onesent-ibm-utf8.txt 
و# نشر العدل من خلال قضاء مستقل .
$ java -cp stanford-parser.jar -mx500m edu.stanford.nlp.parser.lexparser.LexicalizedParser -escaper edu.stanford.nlp.trees.international.arabic.IBMArabicEscaper arabicFactored.ser.gz arabic-onesent-ibm-utf8.txt
Loading parser from serialized file arabicFactored.ser.gz ... done [9.3 sec].
Parsing file: arabic-onesent-ibm-utf8.txt with 1 sentences.
Parsing [sent. 1 len. 8]: و نشر العدل من خلال قضاء مستقل .
(ROOT
  (S (CC و)
    (VP (VBD نشر)
      (NP (DTNN العدل))
      (PP (IN من)
        (NP (NN خلال)
          (NP (NN قضاء) (JJ مستقل)))))
    (PUNC .)))

Parsed file: arabic-onesent-ibm-utf8.txt [1 sentences].
Parsed 8 words in 1 sentences (5.87 wds/sec; 0.73 sents/sec).
</pre>
</li>

<li><h4><a name="j">Can you get dependencies output from the Arabic
parser?</a></h4> 
<p>
You can ask for dependencies output, with the <code>-outputFormat
dependencies</code> option.  At present, there is no typed dependencies
(grammatical relations) analysis available for Arabic, and so asking for
<code>typedDependencies</code> will throw an
<code>UnsupportedOperationException</code>. 
(Caution: With UTF-8 Arabic, the
dependencies output may appear to be reversed, because dependencies are
being displayed right-to-left (depending on the bidi support of your
terminal program).  But they are correct, really.)
</p>
</li>

<li><h4><a name="k">Where does the Arabic-specific source code live?</a></h4>  
<p>
Much of the Arabic-specific code, including the
<code>ArabicHeadFinder</code> and the
<code>ArabicTreebankLanguagePack</code> is defined inside the
<code>edu.stanford.nlp.trees.international.arabic</code> package.  But
parser-specific code and the top level entry to Arabic language
resources is found in the <code>edu.stanford.nlp.parser.lexparser</code>
package.  There, you find the classes
<code>ArabicTreebankParserParams</code> and <code>ArabicUnknownWordSignatures</code>.
</p>
</li>

</ol>

<p>
For general questions, see also the 
<a href="parser-faq.shtml">Parser FAQ</a>.  Please send any other
questions or feedback, or extensions and bugfixes to  
<a href="mailto:parser-user@lists.stanford.edu"><code>parser-user@lists.stanford.edu</code></a>
or
<a href="mailto:parser-support@lists.stanford.edu"><code>parser-support@lists.stanford.edu</code></a>.  
</p>


<!--#include virtual="/footer.html" -->

