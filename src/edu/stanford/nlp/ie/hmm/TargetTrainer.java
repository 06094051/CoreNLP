package edu.stanford.nlp.ie.hmm;

import edu.stanford.nlp.ie.Corpus;
import edu.stanford.nlp.process.Feature;
import edu.stanford.nlp.process.FeatureValue;
import edu.stanford.nlp.process.NumAndCapFeature;
import edu.stanford.nlp.util.ArrayUtils;
import edu.stanford.nlp.stats.ClassicCounter;
import java.io.PrintWriter;
import java.util.Iterator;
import java.util.Properties;

/**
 * Trains a small target HMM on target sequences only.  This can be done
 * using either a fixed structure, or through structure learning.
 * The class learns HMM structures by searching the space
 * of structures using simple add sequence and state operators
 * and using likelihood as a scoring function.
 *
 * @author Jim McFadden
 * @author Christopher Manning
 * @author Huy Nguyen (htnguyen@cs.stanford.edu)
 */
public class TargetTrainer {

  /**
   * These variables are used when doing structure learning
   */
  private double bestResult; // the mdlScore of the best structure
  TargetStructure argBest; // the best structure
  private boolean improving;
  private boolean oneWorse;
  private HMM best;

  /**
   * Constructs a new TargetTrainer.
   */
  public TargetTrainer() {
  }

  /**
   * Trains a target HMM for the given <tt>targetField</tt> on the
   * <tt>trainDocs</tt> according to the properties specified by
   * <tt>props</tt>.
   *
   * @param trainDocs   the training corpus
   * @param targetField the target field generated by the HMM
   * @param props       the properties used to train the target HMM.
   *                    See the {@link Extractor} javadoc for more details
   * @param verbose     if true, prints full output
   * @see Extractor
   */
  public HMM train(Corpus trainDocs, String targetField, Properties props, boolean verbose) {
    String propField;
    String propValue;
    String targetType;
    int numTargetStates;
    boolean trainNow = !("conditional").equals(props.getProperty("trainType"));

    // check target specific properties first
    propField = targetField + ".targetType";
    propValue = props.getProperty(propField);
    if (propValue != null) {
      targetType = propValue;
    }
    // default target type if none specified
    else {
      targetType = props.getProperty("targetType");
    }

    propField = targetField + ".nts";
    propValue = props.getProperty(propField);
    if (propValue != null) {
      numTargetStates = Integer.parseInt(propValue);
    }
    // default nts if none specified
    else {
      numTargetStates = Integer.parseInt(props.getProperty("nts"));
    }

    if (verbose) {
      System.err.println("Target type for target " + targetField + ": " + targetType);
      if (!targetType.equals("learned")) {
        System.err.println("Num target states: " + numTargetStates);
      }
    }

    Corpus targetDocs = new Corpus(trainDocs); // copy for current field
    targetDocs.retainOnlyTarget(targetField);

    if (verbose) {
      System.err.println("Training the " + targetField + " target HMM on " + targetDocs.size() + " mini-documents.");
    }

    HMM thmm = null;
    if (targetType.equals("learned") || targetType.equals("lchain")) {
      TargetTrainer tt = new TargetTrainer();
      props.setProperty("curTargetType", targetType);
      thmm = learnBySearching(targetDocs, targetField, props, verbose);
    } else if (targetType.equals("learned2")) {
      TargetTrainer tt = new TargetTrainer();
      thmm = learnByPruning(targetDocs, targetField, props, verbose);
    } else if (targetType.equals("dlramt")) {
      // HN: special type added for experiments
      thmm = idealDlramt();
    } else {
      Structure ts = null;
      if (targetType.equals("ergodic")) {
        // ergodic target structure
        ts = new TargetStructure(numTargetStates, true);
      } else {
        // chain target structure
        ts = new TargetStructure(numTargetStates);
        ts.initializeTransitions();
      }
      thmm = new HMM(ts, HMM.TARGET_HMM);
    }

    // don't train until after merging if using conditional training
    if (trainNow) {
      thmm.train(targetDocs, props, verbose);
    }
    // must set target fields explicitly since we're not training
    else {
      thmm.setTargetFields(targetDocs.getTargetFields());
    }
    return thmm;
  }


  /**
   * Finds a good structure and parameters for an HMM to represent the given
   * target in the given training docs, by training on a large ergodic structure
   * and then pruning the unnecessary states by merging states with a low information radius.
   * If <tt>verbose</tt> is true, prints
   * a lot of stuff to stderr in the process.
   * checks <tt>props</tt> for the number of target states to begin with
   */
  public HMM learnByPruning(Corpus trainDocs, String targetField, Properties props, boolean verbose) {
    if (props == null) {
      props = Extractor.getDefaultProperties();
    }
    int nts = Integer.parseInt(props.getProperty("nts"));

    // Get the Feature that is used for unknown words
    Feature f = null;
    try {
      f = (Feature) Class.forName(props.getProperty("unkFeature")).newInstance();
    } catch (Exception e) {
      System.err.println("Feature class specified in properties file not found: " + e);
      System.err.println("Using default edu.stanford.nlp.ie.hmm.NumAndCapFeature instead.");
      f = new NumAndCapFeature();
    }

    // HN TODO: Remove
    /*
  Corpus testDocs=(Corpus)trainDocs.splitFrom(0.0,0.1);
  System.err.println("Testing on "+testDocs.size()+" documents");
  trainDocs=(Corpus)trainDocs.splitFrom(0.1,0.9);
  System.err.println("Training on "+trainDocs.size()+" documents");
     */

    Structure ts = new TargetStructure(nts, true);
    HMM hmm = new HMM(ts, HMM.TARGET_HMM);
    hmm.train(trainDocs, props, verbose);

    // HN TODO: Remove.  Used for experimentation on gains from pruning
    /*
HMM[] targets=new HMM[]{hmm};
HMM merged=new HMM(contextHMM,targets,true);
HMMTester tester=new HMMTester(merged);
double F1=tester.test(testDocs,verbose); // DOESN'T WORK (testing on targets only)
System.err.println("Pre-pruned F1: "+F1);
     */

    double mdlScore = hmm.mdlScore(trainDocs);
    System.err.println("Pre-pruned MDL: " + mdlScore);
    //try { HMMGrapher.showHMMGraph(hmm,"MDL: "+mdlScore+" (pre-pruned)"); } catch(TGException e) { }


    while (hmm.getStates().length > 0) {
      State[] states = hmm.getStates();

      // use gammas calculated during EM as priors for being in each state
      double[] gammas = hmm.getGammas();

      // remove GHOST_TOWN states
      for (int i = states.length - 1; i >= 0; i--) {
        if (states[i].emit instanceof ConstantEmitMap && ((ConstantEmitMap) states[i].emit).getString().equals("GHOST_TOWN")) {
          System.err.println("Removing GHOST_TOWN state: " + i);
          states[i].emit.printEmissions(new PrintWriter(System.err, true), false);
          for (int j = 0; j < states.length; j++) {
            // remove transitions to the GHOST_TOWN state
            states[j].transition = ArrayUtils.removeAt(states[j].transition, i);
          }
          gammas = ArrayUtils.removeAt(gammas, i);
          states = (State[]) ArrayUtils.removeAt(states, i);
        }
      }

      // make incoming transitions into a probability distribution by reversing the arrows
      // i.e. we look at P(i->j) instead of P(j->i) for the incoming transitions for i
      double[][] backTransitions = new double[states.length][states.length];
      // compute backTransitions
      for (int i = 0; i < states.length; i++) {
        double[] transitions = states[i].transition;
        for (int j = 0; j < states.length; j++) {
          if (gammas[j] == 0) {
            backTransitions[i][j] = 0.0;
          }
          // P(i|j) == P(j|i)P(i)/P(j)
          else {
            backTransitions[i][j] = transitions[j] * gammas[i] / gammas[j];
          }
        }
      }

      // reduce emissions to features for KL divergence computation
      FeatureMap[] featureMaps = new FeatureMap[states.length];
      for (int i = 0; i < featureMaps.length; i++) {
        featureMaps[i] = new FeatureMap(f);
      }

      for (int i = State.STARTIDX + 1; i < states.length; i++) {
        EmitMap emit = states[i].emit;
        if (!(emit instanceof ConstantEmitMap)) {
          for (Iterator iter = emit.getCounter().keySet().iterator(); iter.hasNext();) {
            String word = (String) iter.next();
            double val = emit.get(word);
            featureMaps[i].addToCount(word, val);
          }
        }
      }

      double minIRad = Double.POSITIVE_INFINITY;
      int argminIRadi = -1;
      int argminIRadj = -1;
      // find the state with the minimum information radius with another state
      for (int i = State.STARTIDX + 1; i < states.length; i++) {
        for (int j = i + 1; j < states.length; j++) {
          //kl divergence D(p||q)=sum(p log(p|q))
          //Information Radius (irad) = D(p||q)+D(q||p)
          double iRad = 0.0;

          // iterate over feature probabilities
          FeatureValue[] features = f.allValues();
          for (int k = 0; k < features.length; k++) {
            double p = featureMaps[i].getProb(features[k]);
            double q = featureMaps[j].getProb(features[k]);
            iRad += irad(p, q);
          }

          // iterate over emissions
          ClassicCounter vocab = hmm.getVocab();
          Iterator it = vocab.keySet().iterator();
          while (it.hasNext()) {
            String word = (String) it.next();
            double p = states[i].emit.get(word);
            double q = states[j].emit.get(word);
            iRad += irad(p, q);
          }

          // iterate over transitions probabilities
          double[] t1 = states[i].transition;
          double[] t2 = states[j].transition;
          for (int k = 0; k < t1.length; k++) {
            // forward transitions
            double p = t1[k];
            double q = t2[k];
            iRad += irad(p, q);

            // backward transitions
            p = backTransitions[i][k];
            q = backTransitions[j][k];
            iRad += irad(p, q);
          }

          if (iRad < minIRad) {

            minIRad = iRad;
            argminIRadi = i;
            argminIRadj = j;
          }
        }
      }

      ts = new Structure(states);

      // merge states with smallest KL divergence
      int mergeTarget = argminIRadi; // state i we're merging j into
      int mergeSource = argminIRadj; // state j we're collapsing into i
      System.err.println("merging states: " + mergeTarget + " and " + mergeSource);

      State[] newStates = new State[states.length - 1];
      for (int i = 0; i < states.length; i++) {
        if (i == mergeSource) {
          continue; // eliminating this state
        }
        int newStateIndex = (i > mergeSource) ? (i - 1) : i; // index once mergeSource is removed
        newStates[newStateIndex] = new State(states[i].type, states[i].emit, states.length - 1);

        if (i == mergeTarget) { // for state mergeTarget, merge in parameters from mergeSource

          // average mergeTarget and mergeSource's outgoing transitions
          for (int j = 0; j < states[mergeTarget].transition.length; j++) {
            int newIndex = (j > mergeSource) ? (j - 1) : j; // shift indices past mergeSource down one
            /*
            System.err.println("j: "+j+"/"+states[mergeTarget].transition.length+","+states[mergeSource].transition.length);
            System.err.println("newIndex: "+newIndex+"/"+newStates[mergeTarget].transition.length);
            System.err.println("mergeTarget: "+mergeTarget+"/"+states.length);
            System.err.println("mergeSource: "+mergeSource+"/"+states.length);
            System.err.println("---");
            */
            double avgTransition = average(states[mergeTarget].transition[j], states[mergeSource].transition[j]);
            if (j == mergeSource) {
              // transition from target to source is now part of target's self-loop so avg it in
              newStates[mergeTarget].transition[mergeTarget] = (avgTransition + newStates[mergeTarget].transition[mergeTarget]) * 0.5;
            } else {
              newStates[mergeTarget].transition[newIndex] = avgTransition;
            }
          }

          // average mergeTarget and mergeSource's emissions
          ClassicCounter vocab = hmm.getVocab();
          Iterator it = vocab.keySet().iterator();
          while (it.hasNext()) {
            String word = (String) it.next();
            newStates[mergeTarget].emit.set(word, average(states[mergeTarget].emit.get(word), states[mergeSource].emit.get(word)));
          }
        } else { // for other states, aggregate outgoing transition mass to mergeSource and meregTarget
          for (int j = 0; j < states[i].transition.length; j++) {
            int newIndex = (j > mergeSource) ? (j - 1) : j; // shift indices past mergeSource down one
            if (j == mergeTarget) { // add transitions to mergeSource into mergeTarget
              newStates[newStateIndex].transition[mergeTarget] = states[i].transition[mergeTarget] + states[i].transition[mergeSource];
            } else if (j != mergeSource) {  // copy transitions for non-merging states (nothing changes)
              newStates[newStateIndex].transition[newIndex] = states[i].transition[j];
            }
          }
          // Since the transitions into mergeSource are spread throughout
          // the states, mixing in the transitions to mergeSource into
          // mergeTarget on per state basis will not in general result in
          // a normalized distribution.  So we normalize here.
          //Structure.normalize(transition);
        }
      }

      // use new states
      hmm = new HMM(newStates, HMM.TARGET_HMM);
      //try { HMMGrapher.showHMMGraph(hmm,"MDL: "+mdlScore+" (merged "+mergeTarget+" and "+mergeSource+")"); } catch(Exception e) { e.printStackTrace(); }
      Properties props2 = new Properties(props);
      props2.setProperty("initEmissions", "false");
      hmm.train(trainDocs, props2, verbose);
      double newScore = hmm.mdlScore(trainDocs);
      System.err.println("MDL Score: " + newScore);
      //try { HMMGrapher.showHMMGraph(hmm,"MDL: "+newScore+" (merged "+mergeTarget+" and "+mergeSource+")"); } catch(Exception e) { e.printStackTrace(); }
      if (newScore >= mdlScore) {
        mdlScore = newScore;
      } else {
        break;
      }
    }
    // HN TODO: Remove.  Used for experimentation on gains from pruning
    /*
    targets[0]=hmm;
    merged=new HMM(contextHMM,targets,true);
    tester=new HMMTester(merged);
    F1=tester.test(testDocs);
    System.err.println("Post-pruned F1: "+F1);
    */

    return hmm;
  }

  /**
   * Returns kl(pi,(pi+qi)/2) + kl(qi,(pi+qi)/2).
   */
  private static double irad(double pi, double qi) {
    double avg = (pi + qi) * 0.5;
    return (kl(pi, avg) + kl(qi, avg));
  }

  /**
   * Returns pi*Log(pi/qi). Returns 0 if p and q are 0.
   */
  private static double kl(double pi, double qi) {
    if (pi == 0) {
      return (0); // 0Log0=0
    }
    return (pi * Math.log(pi / qi));
  }

  private double average(double d1, double d2) {
    //return Math.sqrt(d1*d2);
    return 0.5 * (d1 + d2);
  }

  /**
   * Finds a good structure and parameters for an HMM to represent the given
   * target in the given training docs, using a greedy search of the structure space.
   * If <tt>verbose</tt> is true, prints
   * a lot of stuff to stderr in the process.
   * The <code>props</code> argument is just passed on to
   * <code>HMM.train()</code> -- no properties are tested in this method.
   */
  public HMM learnBySearching(Corpus trainDocs, String targetField, Properties props, boolean verbose) {
    TargetStructure start = new TargetStructure(1, false);
    start.addSelfLoops(); // enrich structure for training
    HMM hmm = new HMM(start, HMM.TARGET_HMM);
    hmm.train(trainDocs, props, verbose);
    //double result = hmm.logLikelihood(trainDocs);
    double result = hmm.mdlScore(trainDocs);
    if (verbose) {
      System.err.println("..............................");
      System.err.println("Initial structure:");
      System.err.println(start);
      // note that calculation below mixes training and held out data
      // sensible??
      System.err.println("mdl score = " + result);
    }

    bestResult = result;
    argBest = start;
    int depth = 0;
    TargetStructure current = start;

    improving = true;
    oneWorse = false;

    while (improving && depth < 10) {
      if (verbose) {
        System.err.println("expanding Nodes...");
      }
      current = expandNode(current, trainDocs, props, verbose);
      depth++;
    }

    best = new HMM(argBest, HMM.TARGET_HMM);
    best.train(trainDocs, props, verbose);

    if (verbose) {
      System.err.println();
      System.err.println("Search concluded");
      System.err.println(argBest);
      System.err.println("Likelihood= " + bestResult);
      System.err.println("Depth reached " + depth);
    }

    return (best);
  }


  /**
   * Does all the HMM-expanding operations to parent structure.
   *
   * @return The best child structure (after one greedy search step)
   *         If target type is <tt>lchain</tt> returns the chain lengthened by 1
   */
  private TargetStructure expandNode(TargetStructure parent, Corpus train, Properties props, boolean verbose) {
    HMM hmm;
    double max = Double.NEGATIVE_INFINITY;
    double result;
    int argmax = -1;

    boolean lchain = "lchain".equals(props.getProperty("curTargetType"));
    int numOps = (lchain) ? 1 : 1 + parent.numTargets();
    TargetStructure[] children = new TargetStructure[numOps];


    if (verbose) {
      System.err.println();
      System.err.println("Expanding structure: " + numOps + " children to check");
      System.err.println("-------------------");
    }
    if (lchain) {
      // evaluate and return single child
      children[0] = (TargetStructure) parent.copy();
      children[0].lengthenTarget(0);
      children[0].initializeTransitions();
      hmm = new HMM(children[0], HMM.TARGET_HMM);
      hmm.train(train, props, verbose);
      max = hmm.mdlScore(train);
      argmax = 0;
    } else {
      for (int k = 0; k < numOps; k++) {
        children[k] = doOp(parent, k, verbose);
        children[k].addSelfLoops(); // enrich structure for training
        hmm = new HMM(children[k], HMM.TARGET_HMM);
        hmm.train(train, props, verbose);
        //result = hmm.logLikelihood(train);
        result = hmm.mdlScore(train);
        if (verbose) {
          System.err.println("..............................");
          // note that calculation below mixes training and held out data
          // sensible??
          System.err.println("log likelihood = " + hmm.logLikelihood(train));
          System.err.println("..............................");
          System.err.println("mdl Score: " + result);
        }
        if (result > max) {
          max = result;
          argmax = k;
        }
      }
    }

    if (verbose) {
      System.err.println("-------------------------------------------");
      System.err.println("Done expanding");
      System.err.println("-------------------------------------------");
      System.err.println("Max was " + argmax);
      System.err.println("likelihood score = " + max);
      System.err.println("State structure (rows are sequences)");
      System.err.println(children[argmax]);
      System.err.println("-------------------------------------------");
    }

    if (max > bestResult) {
      bestResult = max;
      argBest = children[argmax];
      oneWorse = false;
    } else if (oneWorse) {
      improving = false;
    } else {
      oneWorse = true;
    }

    return children[argmax];
  }


  private TargetStructure doOp(TargetStructure parent, int n, boolean verbose) {
    TargetStructure child = (TargetStructure) parent.copy();
    if (verbose) {
      System.err.println();
    }
    switch (n) {
      case 0:
        if (verbose) {
          System.err.println("Operation 0: Adding disjunction length 1");
        }
        child.addTarget(1);
        break;

      default:
        if (n - 1 < child.numTargets()) {
          if (verbose) {
            System.err.println("Operation " + n + ": Lengthening sequence " + (n - 1));
          }
          child.lengthenTarget(n - 1);
        } else {
          if (verbose) {
            System.err.println("ERROR: n out of range: " + n);
          }
        }
    }
    return child;
  }

  /**
   * "Ideal" dlramt HMM designed designed by Chris.
   */
  private static HMM idealDlramt() {
    TargetStructure ts = new TargetStructure();
    int state;
    state = ts.splitState(2);
    ts.insertStateAfter(state, Structure.TARGET_TYPE);
    state = ts.splitState(2);
    ts.insertStateAfter(state, Structure.TARGET_TYPE);
    ts.addTransition(state, State.FINISHIDX);
    ts.insertStateAfter(2, Structure.TARGET_TYPE);
    state = ts.splitState(2);
    ts.insertStateAfter(state, Structure.TARGET_TYPE);
    HMM thmm = new HMM(ts, HMM.TARGET_HMM);
    /* try {
          HMMGrapher.showHMMGraph(thmm,"ideal dlramt");
       } catch(Exception e) {}
     */
    return (thmm);
  }
}

